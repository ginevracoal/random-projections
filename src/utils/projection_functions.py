import time
import numpy as np
import tensorflow as tf
from sklearn.random_projection import GaussianRandomProjection

from utils.plot import rgb2gray
from utils.data import save_to_pickle


def compute_projections(input_data, random_seeds, n_proj, size_proj, projection_mode, translation=None):
    """
    Computes `n_proj` projections of the whole input data on a randomly chosen subspace of size `size_proj`.
    The subspace is generated by randomly chosen vectors and translated with the input data centroid.

    :param input_data: high dimensional input data, shape=(batch_size, rows, cols, channels), type=np.ndarray
    :param random_seeds: random seeds for the projections, type=list
    :param n_proj: number of projections, type=int
    :param size_proj: size of a projection, type=int
    :return: random projections of input_data, type=np.ndarray, shape=(n_proj, batch_size, size, size, channels)
    """

    print("Input shape: ", input_data.shape)
    print("\nComputing ",n_proj,"random projections in ",projection_mode,"mode.")

    projections = []
    inverse_projections = []
    for proj_idx in range(n_proj):
        projection, inverse_projection = compute_single_projection(input_data, random_seeds[proj_idx],
                                                                                size_proj, projection_mode,
                                                                                translation=translation)
        projections.append(projection)
        inverse_projections.append(inverse_projection)
    projections = np.array(projections)
    inverse_projections = np.array(inverse_projections)

    print("Projected data dimensions:", projections.shape)
    return projections, inverse_projections


def compute_single_projection(input_data, seed, size_proj, projection_mode, translation=None):
    """
    Computes a single projection of the whole input data and the associated inverse projection using Moore-Penrose
     pseudoinverse.
    The subspace is generated by randomly chosen vectors and translated with the input data centroid.

    :param input_data: high dimensional input data, type=np.ndarray, shape=(batch_size, rows, cols, channels)
    :param seed: random seed for projection
    :param size_proj: size for the projections
    :param projection_mode: choose computation mode for projections.
                            Supported modes are "flat","channels", "one_channel" and "grayscale"
    :return:
    :param projection: projection of the whole `input_data`
                       type=np.ndarray, shape=(batch_size, size, size, channels)
    :param inverse_projection: inverse projection of the projected points
                               type=np.ndarray, shape=(batch_size, rows, cols, channels)
    """

    if projection_mode == "flat":
        projection, inverse_projection = flat_projection(input_data=input_data, size_proj=size_proj, random_seed=seed,
                                                         translation=translation)
    elif projection_mode == "channels":
        projection, inverse_projection = channels_projection(input_data=input_data, size_proj=size_proj,
                                                             random_seed=seed, translation=translation)
    elif projection_mode == "grayscale":
        projection, inverse_projection = grayscale_projection(input_data=input_data, size_proj=size_proj,
                                                              random_seed=seed, translation=translation)
    else:
        raise AssertionError("Set a projection mode: flat, channels, grayscale.")

    return projection, inverse_projection

def tf_flat_projection(input_data, random_seed, size_proj, translation=None):
    """ Computes a projection of the whole input data flattened over channels and also computes the inverse projection.
    It samples `size_proj` random directions for the projection using the given `random_seed`, then translates the
    affine subspace using the input data centroid.

    :param input_data: high dimensional input data, type=tf.tensor, shape=(batch_size, rows, cols, channels)
    :param random_seed: projection seed, type=int
    :param size_proj: size of a projection, type=int
    :return:
    :param projection: random projection of input_data, type=tf.tensor,
                       shape=(batch_size, size_proj, size_proj, channels)
    :param projection: inverse projection of input_data given by the Moore-Penrose pseudoinverse of the projection
                       matrix, type=tf.tensor, shape=(batch_size, size, size, channels)

    """

    input_data = tf.cast(input_data, tf.float32)
    batch_size, rows, cols, channels = input_data.get_shape().as_list()
    n_features = rows * cols * channels
    n_components = size_proj * size_proj * channels

    if translation is None:
        translation = np.zeros(shape=[1, rows, cols, channels], dtype=np.float32)

    # projection matrices
    projector = GaussianRandomProjection(n_components=n_components, random_state=random_seed)
    proj_matrix = np.float32(projector._make_random_matrix(n_components, n_features))
    pinv = np.linalg.pinv(proj_matrix)

    # compute projections
    flat_images = tf.reshape(input_data, shape=[batch_size, n_features])
    flat_translation = tf.dtypes.cast(tf.reshape(translation, shape=[1,n_features]), dtype=np.float32)
    projected_flat_translation = tf.matmul(a=flat_translation, b=proj_matrix, transpose_b=True)
    projection = tf.matmul(a=flat_images, b=proj_matrix, transpose_b=True) + projected_flat_translation
    inverse_projection = tf.matmul(a=projection-projected_flat_translation, b=pinv, transpose_b=True)

    # # check shapes
    # print(flat_images.shape, proj_matrix.shape, projection.shape)
    # print(flat_translation.shape, proj_matrix.shape, projected_flat_translation.shape)
    # exit()

    # reshape
    projection = tf.reshape(projection, shape=tf.TensorShape([batch_size, size_proj, size_proj, channels]))
    inverse_projection = tf.reshape(inverse_projection, shape=tf.TensorShape([batch_size, rows, cols, channels]))

    # inverse_projection = tf.cast(inverse_projection, tf.float32)
    inverse_projection = mod_invproj(tf.cast(inverse_projection, tf.float32))
    return projection, inverse_projection


def flat_projection(input_data, random_seed, size_proj, translation):
    """ Computes a projection of the whole input data flattened over channels and also computes the inverse projection.
    It samples `size_proj` random directions for the projection using the given random_seed.

    :param input_data: high dimensional input data, type=np.ndarray, shape=(n_samples,rows,cols,channels)
    :param random_seed: projection seed, type=int
    :param size_proj: size of a projection, type=int
    :return:
    :param projection: random projection of input_data, type=np.ndarray, shape=(n_samples,size_proj,size_proj,channels)
    :param inverse_projection: inverse projection of input_data given by the pseudoinverse of the projection matrix,
                               type=np.ndarray, shape=(n_samples,rows,cols,channels)
    """
    sess = tf.Session()
    sess.as_default()

    projection, inverse_projection = tf_flat_projection(input_data, random_seed, size_proj, translation)
    projection = projection.eval(session=sess)
    inverse_projection = inverse_projection.eval(session=sess)
    return projection, inverse_projection


def channels_projection(input_data, random_seed, size_proj, translation):
    """ Computes a projection of the whole input data over each channel, then reconstructs the rgb image.
    It also computes the inverse projections.

    :param input_data: high dimensional input data, type=np.ndarray, shape=(n_samples,rows,cols,channels)
    :param random_seed: projection seed, type=int
    :param size_proj: size of a projection, type=int
    :return:
    :param projection: random projection of input_data, type=np.ndarray, shape=(n_samples,size_proj,size_proj,channels)
    :param inverse_projection: inverse projection of input_data given by the pseudoinverse of the projection matrix,
                               type=np.ndarray, shape=(n_samples,rows,cols,channels)
    """

    samples, rows, cols, channels = input_data.shape
    projection = np.empty((samples, size_proj, size_proj, channels))
    inverse_projection = np.empty(input_data.shape)
    for channel in range(channels):
        single_channel = input_data[:, :, :, channel].reshape(samples, rows, cols, 1)
        channel_projection, channel_inverse_projection = flat_projection(single_channel, random_seed, size_proj,
                                                                         translation)
        projection[:, :, :, channel] = np.squeeze(channel_projection)
        inverse_projection[:, :, :, channel] = np.squeeze(channel_inverse_projection)

    return projection, inverse_projection


def grayscale_projection(input_data, random_seed, size_proj, translation):
    """ Transforms input_data into rgb representation and calls flat_projection on it.
    :param input_data: high dimensional input data, type=np.ndarray, shape=(n_samples,rows,cols,channels)
    :param random_seed: projection seed, type=int
    :param size_proj: size of a projection, type=int
    :return:
    :param projection: random projection of input_data, type=np.ndarray, shape=(n_samples,size_proj,size_proj,channels)
    :param inverse_projection: inverse projection of input_data given by the pseudoinverse of the projection matrix,
                               type=np.ndarray, shape=(n_samples,rows,cols,channels)
    """
    samples, rows, cols, channels = input_data.shape
    grayscale_data = np.array([rgb2gray(rgb_im) for rgb_im in input_data]).reshape((samples, rows, cols, 1))
    # plot_projections([input_data,grayscale_data])
    return flat_projection(grayscale_data, random_seed, size_proj, translation)


def compute_perturbations(input_data, inverse_projections):
    """
    Compute input_data perturbations by adding up inverse_projections on separated color channels.
    :param input_data: input data, type=np.ndarray, shape=(n_samples, rows, cols, channels)
    :param inverse_projections: inverse projections of the input data, type=np.ndarray,
                                shape=(n_proj, n_samples, rows, cols, channels)
    :return: perturbations, type=np.ndarray, shape=(n_samples, rows, cols, channels)
             augmented_inputs are computed by adding perturbations to the inputs, type=np.ndarray,
             shape=(n_samples, rows, cols, channels)
    """
    n_proj = inverse_projections.shape[0]

    perturbations = np.empty(input_data.shape, dtype=float)
    for inverse_projection in inverse_projections:
        perturbations = np.add(perturbations, inverse_projection / n_proj)

    augmented_inputs = np.add(input_data, perturbations)
    augmented_inputs = [mod_augmented_inputs(x.astype(float)) for x in augmented_inputs]
    augmented_inputs = np.array(augmented_inputs)

    return perturbations, augmented_inputs

# TESTING SOME VARIANTS

def mod_invproj(x):
    return x

def mod_pertubations(x):
    return x

def mod_augmented_inputs(x):
    return x

def rescale(x):
    return x*255.0

def normalize(x):
    """
    normalize rgb images.
    :param x: input image, shape=(rows, cols, channels), dtype=float
    :return: normalized image
    """
    return (x-128) / 128

def to_rgb(x):
    sess = tf.Session()
    sess.run(tf.global_variables_initializer())
    min = tf.math.reduce_min(x).eval(session=sess)
    max = tf.math.reduce_max(x).eval(session=sess)
    return 255.0 * tf.div(tf.subtract(x, min), tf.subtract(max, min))

def compute_angle(v1, v2):
    """ Compute the angle between two numpy arrays, eventually flattening them if multidimensional. """
    if len(v1) != len(v2): raise ValueError("\nYou cannot compute the angle between vectors with different dimensions.")
    v1 = v1.flatten()
    v2 = v2.flatten()
    return math.acos(np.dot(v1, v2) / (np.linalg.norm(v1)*np.linalg.norm(v2)) )

def compute_covariance_matrices(x,y):
    """
    Compute within-class and between-class variances on the given data.
    :param x: input data, type=np.ndarray, shape=(n_samples, n_features)
    :param y: data labels, type=np.ndarray, shape=(n_samples, n_classes)
    :return: average within-class variance, average between-class variance
    """
    standardize = lambda x: (x - np.mean(x))/ np.std(x)
    normalize = lambda x: (x - np.min(x))/ (np.max(x)-np.min(x))

    # reshape and standardize data
    n_features =  x.shape[1]
    x = x.reshape(len(x),n_features)
    x = standardize(x)

    # compute mean and class mean
    mu = np.mean(x, axis=0).reshape(n_features,1)
    y_true = np.argmax(y, axis=1)
    mu_classes = []
    for i in range(10):
        mu_classes.append(np.mean(x[np.where(y_true == i)], axis=0))
    mu_classes = np.array(mu_classes).T

    # compute scatter matrices
    data_SW = []
    Nc = []
    for i in range(10):
        a = np.array(x[np.where(y_true == i)] - mu_classes[:, i].reshape(1, n_features))
        data_SW.append(np.dot(a.T, a))
        Nc.append(np.sum(y_true == i))
    SW = np.sum(data_SW, axis=0)
    SB = np.dot(Nc * np.array(mu_classes - mu), np.array(mu_classes - mu).T)

    SW = normalize(SW)
    SB = normalize(SB)
    print("\nWithin-class avg normalized variance:", np.mean(SW))
    print("Between-class avg normalized variance:", np.mean(SB))

    return SW, SB

def compute_distances(x1,x2,ord):
    """
    Computes min, avg and max distances between the inputs and their perturbations
    :param x1: input points, shape=(n_samples, rows, cols, channels), type=np.ndarray
    :param x2: perturbations, shape=(n_samples, rows, cols, channels), type=np.ndarray
    :param ord: norm order for np.linalg.norm
    :return: min, average, max distances between all couples of points, type=dict
    """
    if x1.shape != x2.shape:
        raise ValueError("\nThe arrays need to have the same shape.")
    flat_x1 = x1.reshape(x1.shape[0], np.prod(x1.shape[1:]))
    flat_x2 = x2.reshape(x2.shape[0], np.prod(x2.shape[1:]))
    min = np.min([np.linalg.norm(flat_x1[idx] - flat_x2[idx], ord=ord) for idx in range(len(x1))])
    mean = np.mean([np.linalg.norm(flat_x1[idx] - flat_x2[idx], ord=ord) for idx in range(len(x1))])
    max = np.max([np.linalg.norm(flat_x1[idx] - flat_x2[idx], ord=ord) for idx in range(len(x1))])
    return {"min":min, "max": max}

def covariance_eigendec(np_matrix):
    print("\nmatrix[rows=vars, cols=obs] = \n", np_matrix)
    C = np.cov(np_matrix)
    print("\ncovariance matrix = \n", C)

    eVe, eVa = np.linalg.eig(C)

    plt.scatter(np_matrix[:, 0], np_matrix[:, 1])
    for e, v in zip(eVe, eVa.T):
        plt.plot([0, 3 * np.sqrt(e) * v[0]], [0, 3 * np.sqrt(e) * v[1]], 'k-', lw=2)
    plt.title('Transformed Data')
    plt.axis('equal')
    os.makedirs(os.path.dirname(RESULTS), exist_ok=True)
    plt.savefig(RESULTS+"covariance.png")
